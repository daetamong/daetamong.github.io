---
layout: post
title: L1/L2 Regularizaion에 대해 알아보자
subtitle: Regularization의 개념과 L1, L2의 차이점에 대해 알아보자
categories: 딥러닝
tags: [딥러닝]
---

`개인적으로 공부한 내용을 포스팅하기 때문에 잘못된 내용이 있을 수 있습니다. 만약 틀린 내용이 있다면 적극적인 피드백 부탁드립니다^^`


아마 간단한 프로젝트나 분석, 개발 실무를 하다보면 과적합 문제를 접해봤을 것이다. 그만큼 우리에게 편안한 데이터를 주는 경우는 많이 없기 때문이다. (이게 은근히 괴롭다...)

어쨋든 이러한 과적합 문제를 해결하는 방법은 여러가지가 있는데, 뭐가 있는지 한번 보자.

- 배치 정규화 (Batch Normalization)

- 정규화 (Weight Regularization)

- Dropout

과적합을 막는 대표적인 방법은 위의 3개 정도가 있곘다. (더 많지만)

물론 나머지도 다 정리할 예정이지만 이번 포스팅에서는 L1, L2 regularization에 대해서 정리해볼 예정이다.



### 과적합이 뭐자...?

과적합을 방지하는 방법에 대해 정리하기 전에 **과적합**이 무엇인지 알아보는게 좋을 것 같아 정리해본다.

과적합은 OverFitting이라고도 불리는데, 모델을 개발할 때 train과 test 데이터로 나눈 뒤에 train 데이터로 모델을 학습하고 test 데이터로 개발한 모델의 성능을 확인하는 것이 일반적이다.

아래의 그래프를 먼저 보자

![do-messenger_screenshot_2023-12-14_13_44_53](https://github.com/daetamong/daetamong.github.io/assets/111731468/d306c8c1-2eaa-421f-834b-8d945eaa7dd9)

두 개의 그래프 중에서 어떤 모델이 더 정확할 것 같은가?

물론 이 상태로 봤을 때는 왼쪽의 모델이 거의 모든 데이터를 다 맞췄을 것이다.

그런데 만약 이렇게 학습된 모델에 새로운 형태의 데이터가 들어왔을 때도 과연 잘 맞출까?

오히려 오른쪽의 모델이 실제 test 데이터가 들어왔을 때 더 잘 맞출 수도 있다.

이처럼 train 데이터에 과하게 모델에 반영이 되어 train 데이터를 다 맞추지만 새로운 데이터(=test)가 들어왔을 때, 거의 하나도 맞추지 못하는 현상을 과적합이라고 한다. (그냥 내가 이해하기 쉽게 풀어 썼다 ㅎㅎ)

어쨋든 이렇게 train 데이터에 맞춤형으로 모델이 개발되면 실제 성능 테스트를 할 때는 좋지 못하게 된다. 그래서 우리는 이를 해결할 수 있는 방법에 대해 알아볼 예정이다.