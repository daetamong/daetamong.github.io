---
layout: post
title: Gradient Descent(경사하강법)이란?
subtitle: Gradient Descent의 개념에 대해 알아보자
categories: 머신러닝
tags: [머신러닝]
---

`개인적으로 공부한 내용을 포스팅하기 때문에 잘못된 내용이 있을 수 있습니다. 만약 틀린 내용이 있다면 적극적인 피드백 부탁드립니다^^`

### Gradient Descent(경사하강법)이란?

우선 경사하강법이 뭔지 바로 정리하고 넘어가려고 한다. 왜냐하면 대략적으로 어떤 개념인지 알고 시작하는게 이후에 있을 내용을 이해하는 데 도움이 될 것 같은 개인적인 생각 때문이다.

그래서 경사하강법이 먼지 정리를 해보자면

> **경사하강법은** Cost function을 최소화하는 알고리즘으로,  가중치를 반복적으로 증가/감소시켜가며 함수 값이 최소가 되도록(=기울기가 0이 되도록) 하는 알고리즘이다.

이렇게만 정리를 하면 나도 이해가 잘 되지 않고, 우연히? 이 글을 보는 사람들도 이해가 가지 않을 수 있다.

그래서 왜 머신러닝, 딥러닝에서 경사하강법이 중요한 개념 중 하나로 인식되고 있는지, 그리고 이 개념을 실제 모델 학습에서 어떻게 쓰는지 차례차례 살펴보면서 이해해보려 한다.



### Cost Function(=비용함수)이란?

여기서 또 새로운 개념이 하나가 더 있는데 '비용함수'라는 개념이 있다.

비용함수는 **"최적의 가중치를 찾기 위한 기준이 되는 함수"**이다.

머신러닝에서는 비용함수가 최소가 되도록 최적의 파라미터를 찾는 과정을 최적화라고 하는데, 이 떄 사용하는 기준이 비용함수이다.

비용함수에도 여러가지 식이 있는데, 대표적인으로 MSE(Mean Squared Error, 평균 제곱 오차)와 MAE(Mean Absolute Error, 평균 절대 오차)가 있다.

하나씩 살펴보자!

> 1. MSE = $\frac1n\sum_{i=1}^n(y_i - \hat{y})^2$

> 2. MAE = $\frac1n\sum_{i=1}^n|y_i - \hat{y}|$

위 두 식의 차이는 제곱을 했는가 아니면 절대값을 씌었는가라는 차이점이 있는데, 물론 상황에 따라 다르겠지만 일반적으로는 제곱을 한 MSE를 주로 사용한다.

그 이유는 크게 두 가지 정도가 있다.

첫 번째 이유로는 실제값($y_i$)과 예측값(=$hat{y}^2$)의 차이를 더 크게 만들어줌으로써 업데이트할 가중치에 더 큰 패널티를 부여하기 위함이다.

두 번째는 컴퓨터 연산량?의 이류로 절대값을 씌운 case에 좀 더 많은 연산량이 부여된다고 한다. 따라서 연산량 부하를 조금이라도 줄이기 위해 절대값보다는 제곱을 씌운 MSE를 더 많이 사용한다.



### 경사하강법을 사용하는 방법은 무엇일까?

이제 경사하강법을 언제 쓰는지를 간단한 예시를 통해 한번 알아보자!

우리는 [1,2,3]이라는 Input Data를 갖고 있고, 이 데이터를 어떤 회귀 모형에 넣었을 때 [3,5,7]이라는 결과를 얻었을 때, 우리는 회귀모형식을 알고 싶다고 하자.

데이터가 3개 밖에 없으니 우리가 직접 손으로 계산하여 회귀모형이 대략 f(x) = 2x + 1가 되지 않을까 유추할 수 있다.

그런데, 만약 수십만개의 데이터가 있다면 과연 우리가 모형식을 손으로 계산할 수 있을까?

이처럼 직접 계산하기가 현실적으로 불가능한 경우에 모형식의 파라미터를 추정할 때 경사하강법을 사용한다.

위의 데이터를 그려보면 아래처럼 점이 찍힐 것이다. 그리고 주황색 선처럼 모형식을 유추하여 그릴 수 있을 것이다.

![do-messenger_screenshot_2023-11-16_15_26_00](https://github.com/daetamong/daetamong.github.io/assets/111731468/269f2789-e812-410e-9881-0811e0f3142b)

하지만 만약 첫 추정 모형식을 y = x라고 하자. 그렇다면 아래의 그림처럼 실제 데이터와 모형식 간의 오차가 발생할 것이다.

![do-messenger_screenshot_2023-11-16_15_30_40](https://github.com/daetamong/daetamong.github.io/assets/111731468/4c66e97d-5c25-4c96-930f-452bf96436c7)

그럼 이제 우리는 이 오차가 적어지도록 파라미터를 다시 재지정해줘야 한다.

